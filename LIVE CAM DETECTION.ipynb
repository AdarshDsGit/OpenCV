{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1bd344f",
   "metadata": {},
   "source": [
    "# FACE AND EYE DETECTION USING HAAR CASCADE CLASSEIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2e3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075c536",
   "metadata": {},
   "source": [
    "Tuning Cascade Classifiers\n",
    "ourClassifier.detectMultiScale(input image, Scale Factor , Min Neighbors)\n",
    "\n",
    "Scale Factor\n",
    "Specifies how much we reduce the image size each time we scale. E.g. in face detection we typically use 1.3. This means we reduce the image by 30% each time itâ€™s scaled. Smaller values, like 1.05 will take longer to compute, but will increase the rate of detection.\n",
    "\n",
    "Min Neighbors\n",
    "Specifies the number of neighbors each potential window should have in order to consider it a positive detection. Typically set between 3-6. It acts as sensitivity setting, low values will sometimes detect multiples faces over a single face. High values will ensure less false positives, but you may miss some faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f8b147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:20: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_25356\\4100795114.py:20: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "##OpenCV's CascadeClassifier function\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"C:/Project/opencv/Haarcascades/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "# we are coverting it to 1 channel for processing quicker\n",
    "image = cv2.imread('C:/Project/opencv/sampleimages/obama.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67c051",
   "metadata": {},
   "source": [
    "# LET'S COMBINE FACE AND EYE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbba9c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_25356\\3271363300.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "eye_classifier = cv2.CascadeClassifier('C:/Project/opencv/Haarcascades/haarcascade_eye.xml')\n",
    "face_classifier = cv2.CascadeClassifier(\"C:/Project/opencv/Haarcascades/haarcascade_frontalface_default.xml\")\n",
    " \n",
    "image = cv2.imread('C:/Project/opencv/sampleimages/Elon.webp')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('Elon',image)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
    "        cv2.imshow('image',image)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568e692",
   "metadata": {},
   "source": [
    "# Live face & eye detection, keeping the face inview at all times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61899edb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f03f09b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m _, frame \u001b[38;5;241m=\u001b[39m video_capture\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     17\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 18\u001b[0m canvas \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo\u001b[39m\u001b[38;5;124m'\u001b[39m, canvas)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(gray, frame)\u001b[0m\n\u001b[0;32m      6\u001b[0m roi_gray \u001b[38;5;241m=\u001b[39m gray[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[0;32m      7\u001b[0m roi_color \u001b[38;5;241m=\u001b[39m frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[1;32m----> 8\u001b[0m eyes \u001b[38;5;241m=\u001b[39m \u001b[43meye_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (ex, ey, ew, eh) \u001b[38;5;129;01min\u001b[39;00m eyes:\n\u001b[0;32m     10\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(roi_color, (ex, ey), (ex\u001b[38;5;241m+\u001b[39mew, ey\u001b[38;5;241m+\u001b[39meh), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining a function that will do the detections\n",
    "def detect(gray, frame):\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray, 1.1, 3)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812d552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210f9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c959fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681747b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a272e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72472e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
